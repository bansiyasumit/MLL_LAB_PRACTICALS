
**Student Roll No:** `25901337`
**Course:** Machine Learning Lab
**Language:** Python
**Environment:** Google Colab / Jupyter Notebook

---

## ğŸ“ Repository Structure

```text
StudentRollNo_##/
â”‚
â”œâ”€â”€ easy.ipynb        # Logistic Regression (Baseline)
â”œâ”€â”€ moderate.ipynb    # Linear SVM with Hyperparameter Tuning
â”œâ”€â”€ hard.ipynb        # KNN vs Linear SVM Comparison
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
```

---

## ğŸ“Š Dataset Used

**DS5 â€“ Telco Customer Churn Dataset**
Link: [https://www.kaggle.com/datasets/blastchar/telco-customer-churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

The dataset contains customer demographics, service usage, and billing details, with a binary target variable **`Churn`** indicating whether a customer leaves the service.

---

# ğŸŸ¢ Practical 1 â€“ EASY

## Logistic Regression (Baseline Model)

### ğŸ¯ Objective

To build a **baseline binary classification model** using **Logistic Regression** to predict customer churn and evaluate it using the **ROC-AUC** metric.

### ğŸ§ª Methodology

* Performed basic EDA: dataset shape, missing values, and target distribution
* Visualized churn distribution and monthly charges
* Encoded target variable (`Churn`: Yes â†’ 1, No â†’ 0)
* Applied one-hot encoding to categorical features
* Scaled features using StandardScaler
* Split data into training and validation sets
* Trained a Logistic Regression model

### ğŸ“ˆ Evaluation Metric

* **ROC-AUC Score**

### ğŸ§  Reasoning

Logistic Regression was chosen as a simple and interpretable baseline model. ROC-AUC was used as it evaluates performance across all classification thresholds and is suitable for imbalanced datasets.

---

# ğŸŸ¡ Practical 2 â€“ MODERATE

## Linear Support Vector Machine (SVM)

### ğŸ¯ Objective

To build a **Linear SVM classifier**, tune hyperparameters **`C`** and **`class_weight`**, and evaluate the model using the **F1-score**.

### ğŸ§ª Methodology

* Reused DS5 dataset with fresh preprocessing
* Conducted EDA and visualizations
* Applied one-hot encoding, creating a high-dimensional feature space
* Scaled features (mandatory for SVM)
* Used **GridSearchCV** to tune:

  * `C` (regularization strength)
  * `class_weight` (to handle class imbalance)
* Selected best model based on F1-score

### ğŸ“ˆ Evaluation Metric

* **F1-Score**

### ğŸ§  Reasoning

Linear SVM performs well in high-dimensional spaces. Hyperparameter tuning improves margin control and class balance handling. F1-score was chosen because it balances precision and recall in imbalanced classification problems.

---

# ğŸ”´ Practical 3 â€“ HARD

## KNN vs Linear SVM on Sparse High-Dimensional Data

### ğŸ¯ Objective

To compare **KNN** and **Linear SVM** after one-hot encoding and analyze why **KNN struggles** in high-dimensional sparse feature spaces.

### ğŸ§ª Methodology

* Used DS5 dataset and applied one-hot encoding
* Created a **high-dimensional sparse feature space**
* Scaled features for fair comparison
* Trained:

  * **KNN (distance-based classifier)**
  * **Linear SVM (margin-based classifier)**
* Evaluated both models using **F1-score**

### ğŸ“ˆ Results

* **KNN F1-score:** â‰ˆ 0.51
* **Linear SVM F1-score:** â‰ˆ 0.59

### ğŸ§  Analysis & Discussion

KNN relies on distance calculations, which become unreliable in high-dimensional sparse spaces due to the **curse of dimensionality**. As dimensions increase, distances between points become similar, reducing neighborhood quality. Linear SVM performs better because it focuses on learning an optimal separating hyperplane rather than relying on distance metrics, making it more robust to sparsity.

---

## âœ… Conclusion

* Logistic Regression provides a strong baseline
* Linear SVM outperforms the baseline after tuning
* Linear SVM significantly outperforms KNN in sparse, high-dimensional feature spaces

